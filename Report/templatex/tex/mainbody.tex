%=================================================================
\section{Problem Introduction}\label{sec-intro}


%\todo{Narrow down to a topic; Dig a hole; Fill the hole}
%\todo{Formula for Introduction}



%\gangli{``narrow in on topic'' reminds you 
%that readers and reviewers only know that this is a AI or HTM research paper (and maybe have read the title/abstract). 
%You need to help them figure out what topic and area of research paper this is. 
%You _don't_ need to wax poetic about the topic's importance.}

%\gangli{`dig a hole'' reminds you that 
%you need to convince the reader that there's a problem with the state of the world. 
%Prior work may exist but it's either missing something important or there's a missing opportunity. 
%The reader should be drooling for a bright future just out of reach.}

%\gangli{``fill the hole'' reminds you to show the reader 
%how and why the paper they're reading will fix these problems and deliver us into a better place. 
%You don't need a whirlwind summary of the technical details, 
%but you need readers convinced (and in a good mood) to keep reading.}

%\gangli{A good paper introduction is fairly formulaic. 
%If you follow a simple set of rules, 
%you can write a very good introduction. 
%The following outline can be varied. 
%For example, 
%you can use two paragraphs instead of one, 
%or you can place more emphasis on one aspect of the intro than another. 
%But in all cases, 
%all of the points below need to be covered in an introduction, 
%and in most papers, 
%you don't need to cover anything more in an introduction.}



%\todo{The importance of the area}
%\blindtext
%\todo{Motivation}
Bike sharing systems are a means of renting bicycles where the process of obtaining membership,
rental, and bike return is automated via a network of kiosk locations throughout a city.
Using these systems, people are able rent a bike from a one location and return it to a different place on an as-needed basis.
Currently, there are over 500 bike-sharing programs around the world.



%\todo{The problems faced by most current methods}
%\blindtext
%\todo{What is the specific problem considered in this paper?}
The data generated by these systems makes them attractive for researchers
because the duration of travel, departure location, arrival location, 
and time elapsed is explicitly recorded. 
Bike sharing systems therefore function as a sensor network, 
which can be used for studying mobility in a city. 
In this competition, 
participants are asked to combine historical usage patterns with weather data in order to forecast bike rental demand in the Capital Bikeshare program in Washington, 
D.C.

%In the first paragraph you have established general context and importance. 
%Here you establish specific context and background.

%\todo{What can be addressed by existing methods; Why those problems are challenges to existing methods?}
%\blindtext
%\todo{Contribution}
%"In this paper, we show that ...". 
%This is the key paragraph in the intro - you summarize, 
%in one paragraph, 
%what are the main contributions of your paper given the context 
%you have established in paragraphs 1 and 2. 
%What is the general approach taken? 
%Why are the specific results significant? 
%This paragraph must be really good. 

%\begin{itemize}
	%\item e.g., First ...
	%\item e.g., Second ...
	%\item e.g., Third ...
%\end{itemize}


%\todo{What provides the motivation of this work? What are the research issues? What is the rationale of this work? }
%\blindtext
%\todo{At a high level what are the differences in what you are doing, and what others have done? }


%\todo{What we have done and what are the contributions.}
%\blindtext
%todo{A roadmap for the rest of the paper}




%\missingfigure[figcolor=white]{Testing figcolor}




%\blindmathpaper

\section{Exploratory Data Analysis} \label{sec-preliminaries}


First we can look at the distribution of count, 
the variable which gives the total number of rented bikes for a given training sample. 
The distribution is heavily skewed right  thus is not well approximated by a normal distribution.

We can also visualize the disribution of the total count for different categorical variables, 
such as season, weather, month, and working day. 
We Use box plots, 

\begin{center}
\includegraphics[scale=0.8]{D:/D：downloads/p_working}
\end{center}
\begin{center}
\includegraphics[scale=0.8]{D:/D：downloads/p_holiday}
\end{center}
\begin{center}
\includegraphics[scale=0.8]{D:/D：downloads/p_weather}
\end{center}
\begin{center}
\includegraphics[scale=0.8]{D:/D：downloads/p_season}
\end{center}
We can also plot a correlation heatmap showing the 2D correlation matrix for the features in our dataset. 

\begin{center}
\centering
\includegraphics[scale=0.25]{D:/D：downloads/heatmap}
\centering
\end{center}

Several features have a positive correlation with the total count, such as the hour  (+0.4) , temperature  (+0.39) , and "atemp"  (+0.39) , the feels-like temperature. However temperature and atemp have a correlation of almost  1 , so it may be better to simply remove the atemp data. There is also a clear negative correlation  (−0.32)  between total count and humidity.

There is also a positive correlation  (+0.26)  between the year and bike usage. Our training set contains data over two years, 2011 and 2012.

Overall, there is little correlation between total count and the workingday variable. 

We can visualize how daily usage varies with the continuous weather variables (temperature, atemp, wind speed, and humidity) using a jointplot. 
\begin{center}
	\includegraphics[scale=0.8]{D:/D：downloads/jointplot_windspeed}
\end{center}

\begin{center}
	\includegraphics[scale=0.8]{D:/D：downloads/jointplot_temp}
\end{center}

\begin{center}
	\includegraphics[scale=0.8]{D:/D：downloads/jointplot_humidity}
\end{center}

Here we can see visually the positive correlation between total count and the temperature, as well as the negative correlation between total count and humidity. 
The distributions for workdays and non-workdays are very similar as indicated by the accompanying kde plots.





\section{Data preprocessing} \label{sec-method}


First, note that the total count (the variable we will aim to predict) is the sum of the casual count and the registered count. As such, the test set does not contain data for the casual count or the registered count. We should thus drop casual and registered from our dataframe. Let us also drop atemp since it has almost perfect correlation with temp.

Secondly, note that the testing and training data (with the split made by Kaggle for the purposes of the competition) is determined by the day of the month. The combined data sets represent records ranging from January 2011 to December 2012, with data collected on or before the Day 19 of each month assigned to the training set, and data collected from Day 20 onwards assigned to the testing set by Kaggle. Consequently, we drop all day of the month data from the training set before training our models.

The data set contains a mixture of continuous variables (temperature and windspeed) and categorical variables (such as season, weather type, month, and day of the week). However, the categorical data is expressed as an arbitrary numerical value. Therefore we can use dummy coding, replacing the categorical data with binary dummy variables using the pandas function pd.get_dummies. After this, we also drop one redundant category known as the reference category. For example, only six binary variables are necessary to fully specify the day of the week.

As noted previously, the natural logarithm of count is more normally distributed. Let us replace the target variable count with  y=ln(count+1) . This ensures total counts of  0  are mapped to  0  and not  −∞ . The training data  X  consists of all other data in our dataframe (now  52  features).

Taking the natural log of the count data gives a distribution slightly more normally distributed, as shown above, and also in the quantile-quantile (Q-Q) plots below. Here the quantiles of the data (i.e. the values in order) are plotted against the same quantilies of a theoretical normal distribution.

\begin{center}
	\centering
\includegraphics[scale=0.5]{D:/D：downloads/QQ_plot}
\centering
\end{center}

We split the labelled training set into two sets: one for training our models, and a validation set for determining the best set of hyperparameters.

Finally, we should define a function predict that will report prediction scores for a given model.



\section{Train and Apply models} \label{sec-experiment}

Firstly, we should train our models and select the best one by comparing their RMSLE score.

We apply train data and validation data to the chosen model, such as LinearRegression, Ridge, Lasso, RandomForestRegressor,
GradientBoostingRegressor, XGBRegressor, LGBMRegressor.

The scores of each model are as below.

\vspace{.5cm}

\begin{tabular}{ c | c  }
	\toprule
	Model     &  RMSLE For Each Model         \\
	\midrule
	LinearRegression       & 0.136  \\
	
	Ridge       & 0.137  \\
	
	Lasso       & 0.148  \\
	
	RandomForestRegressor       & 0.084  \\
	
	GradientBoostingRegressor       & 0.080  \\
	
	XGBRegressor      & 0.085  \\
	
	LGBMRegressor      & 0.078  \\
	
	\bottomrule
\end{tabular}

\vspace{.5cm}

We select LGBMRegressor as our best model because of its lowest RMSLE value.

We apply the model above to test data and predict the bike sharing demand.


\begin{center}
	\includegraphics[scale=0.8]{D:/D：downloads/predict_head}
\end{center}


\section{Conclusions} \label{sec-conclusions}


We serve the data set and submit our code and tex file to github.






